{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe5328c",
   "metadata": {},
   "source": [
    "**ANALYSIS NOTEBOOK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1673357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and visualization for analysis of performance\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86f4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the logs of the history files (compatible with .json and .pkl)\n",
    "def plot_training_history(history_path, output_path):\n",
    "    # Determine file extension\n",
    "    _, ext = os.path.splitext(history_path)\n",
    "    \n",
    "    # Load history based on file type\n",
    "    if ext == '.json':\n",
    "        import json\n",
    "        with open(history_path, 'r') as f:\n",
    "            history = json.load(f)\n",
    "    elif ext == '.pkl':\n",
    "        import pickle\n",
    "        with open(history_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use .json or .pkl\")\n",
    "    \n",
    "    # Convert to DataFrame for easier plotting\n",
    "    if isinstance(history, dict):\n",
    "        # If history is a dict with lists as values, convert directly\n",
    "        df = pd.DataFrame(history)\n",
    "    else:\n",
    "        # If history is a list of dicts, convert to DataFrame\n",
    "        df = pd.DataFrame(history)\n",
    "    \n",
    "    # Check for required columns (handle different naming conventions)\n",
    "    train_col = next((col for col in df.columns if 'train' in col.lower() and 'acc' in col.lower()), None)\n",
    "    val_col = next((col for col in df.columns if 'val' in col.lower() and 'acc' in col.lower()), None)\n",
    "    \n",
    "    if train_col is None or val_col is None:\n",
    "        print(f\"Warning: Could not find train/val accuracy columns. Available: {list(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    if 'epoch' in df.columns:\n",
    "        plt.plot(df['epoch'], df[train_col], label='Train Accuracy', marker='o')\n",
    "        plt.plot(df['epoch'], df[val_col], label='Validation Accuracy', marker='s')\n",
    "    else:\n",
    "        plt.plot(df[train_col], label='Train Accuracy', marker='o')\n",
    "        plt.plot(df[val_col], label='Validation Accuracy', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy - {os.path.basename(history_path)}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1dcc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History file paths (may be absent if not generated)\n",
    "distilled_model_history_path = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/logs/distillation_history.json'\n",
    "pruned_model_history_path = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/logs/pruned_history.json'\n",
    "qat_model_history_path = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/logs/qat_history.json'\n",
    "resnet18_model_history_path = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/logs/student_resnet18_history.pkl'\n",
    "teacher_model_history_path = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/logs/teacher_training_history.json'\n",
    "OUTPUT_DIR = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e620fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Plotted distillation_history.json → distilled_model_history.png\n",
      "✓ Plotted pruned_history.json → pruned_model_history.png\n",
      "✓ Plotted qat_history.json → qat_model_history.png\n",
      "✓ Plotted student_resnet18_history.pkl → resnet18_student_model_history.png\n",
      "✓ Plotted teacher_training_history.json → teacher_model_history.png\n"
     ]
    }
   ],
   "source": [
    "# Calling the plotting function for each model\n",
    "history_files = [\n",
    "    (distilled_model_history_path, os.path.join(OUTPUT_DIR, 'distilled_model_history.png')),\n",
    "    (pruned_model_history_path, os.path.join(OUTPUT_DIR, 'pruned_model_history.png')),\n",
    "    (qat_model_history_path, os.path.join(OUTPUT_DIR, 'qat_model_history.png')),\n",
    "    (resnet18_model_history_path, os.path.join(OUTPUT_DIR, 'resnet18_student_model_history.png')),\n",
    "    (teacher_model_history_path, os.path.join(OUTPUT_DIR, 'teacher_model_history.png')),\n",
    "]\n",
    "\n",
    "for history_path, output_path in history_files:\n",
    "    if os.path.exists(history_path):\n",
    "        try:\n",
    "            plot_training_history(history_path, output_path)\n",
    "            print(f\"✓ Plotted {os.path.basename(history_path)} → {os.path.basename(output_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error plotting {os.path.basename(history_path)}: {e}\")\n",
    "    else:\n",
    "        print(f\"⚠ Skipping {os.path.basename(history_path)} - file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d5b1b",
   "metadata": {},
   "source": [
    "## Model comparison: accuracy, size, latency, and FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d5c954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>size_mb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teacher_resnet50</th>\n",
       "      <td>outputs/models/teacher_resnet50.pth</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>7.378359</td>\n",
       "      <td>90.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_resnet18</th>\n",
       "      <td>outputs/models/student_resnet18.pth</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>0.090249</td>\n",
       "      <td>2.516418</td>\n",
       "      <td>42.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruned_model</th>\n",
       "      <td>outputs/models/pruned_model.pth</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.075106</td>\n",
       "      <td>2.513332</td>\n",
       "      <td>42.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilled_model</th>\n",
       "      <td>outputs/models/distilled_model.pth</td>\n",
       "      <td>0.984938</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>2.546458</td>\n",
       "      <td>42.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qat_model</th>\n",
       "      <td>outputs/models/quantized_model.pth</td>\n",
       "      <td>0.983210</td>\n",
       "      <td>0.062404</td>\n",
       "      <td>2.533035</td>\n",
       "      <td>42.729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           checkpoint  accuracy      loss  \\\n",
       "name                                                                        \n",
       "teacher_resnet50  outputs/models/teacher_resnet50.pth  0.983457  0.053061   \n",
       "student_resnet18  outputs/models/student_resnet18.pth  0.974321  0.090249   \n",
       "pruned_model          outputs/models/pruned_model.pth  0.975309  0.075106   \n",
       "distilled_model    outputs/models/distilled_model.pth  0.984938  0.048888   \n",
       "qat_model          outputs/models/quantized_model.pth  0.983210  0.062404   \n",
       "\n",
       "                  latency_ms  size_mb  \n",
       "name                                   \n",
       "teacher_resnet50    7.378359   90.056  \n",
       "student_resnet18    2.516418   42.730  \n",
       "pruned_model        2.513332   42.729  \n",
       "distilled_model     2.546458   42.729  \n",
       "qat_model           2.533035   42.729  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load evaluation results (produced by scripts/evaluation/05_evaluate_model.py)\n",
    "eval_path = '/Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/reports/evaluation_results.json'\n",
    "if not os.path.exists(eval_path):\n",
    "    print('Evaluation results not found at', eval_path)\n",
    "    df = pd.DataFrame()\n",
    "else:\n",
    "    import json\n",
    "    with open(eval_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    # Normalize into a DataFrame\n",
    "    rows = []\n",
    "    for name, info in results.items():\n",
    "        rows.append({\n",
    "            'name': name,\n",
    "            'checkpoint': info.get('checkpoint'),\n",
    "            'accuracy': info.get('accuracy'),\n",
    "            'loss': info.get('loss'),\n",
    "            'latency_ms': info.get('latency_ms'),\n",
    "            'size_mb': info.get('size_mb'),\n",
    "        })\n",
    "    df = pd.DataFrame(rows).set_index('name')\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc8af26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>flops</th>\n",
       "      <th>accuracy_per_mb</th>\n",
       "      <th>accuracy_per_gflop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilled_model</th>\n",
       "      <td>outputs/models/distilled_model.pth</td>\n",
       "      <td>0.984938</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>2.546458</td>\n",
       "      <td>42.729</td>\n",
       "      <td>1.800000e+09</td>\n",
       "      <td>0.023051</td>\n",
       "      <td>0.547188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teacher_resnet50</th>\n",
       "      <td>outputs/models/teacher_resnet50.pth</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>7.378359</td>\n",
       "      <td>90.056</td>\n",
       "      <td>4.100000e+09</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.239868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qat_model</th>\n",
       "      <td>outputs/models/quantized_model.pth</td>\n",
       "      <td>0.983210</td>\n",
       "      <td>0.062404</td>\n",
       "      <td>2.533035</td>\n",
       "      <td>42.729</td>\n",
       "      <td>1.800000e+09</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.546228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruned_model</th>\n",
       "      <td>outputs/models/pruned_model.pth</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.075106</td>\n",
       "      <td>2.513332</td>\n",
       "      <td>42.729</td>\n",
       "      <td>1.800000e+09</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>0.541838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_resnet18</th>\n",
       "      <td>outputs/models/student_resnet18.pth</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>0.090249</td>\n",
       "      <td>2.516418</td>\n",
       "      <td>42.730</td>\n",
       "      <td>1.800000e+09</td>\n",
       "      <td>0.022802</td>\n",
       "      <td>0.541289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           checkpoint  accuracy      loss  \\\n",
       "name                                                                        \n",
       "distilled_model    outputs/models/distilled_model.pth  0.984938  0.048888   \n",
       "teacher_resnet50  outputs/models/teacher_resnet50.pth  0.983457  0.053061   \n",
       "qat_model          outputs/models/quantized_model.pth  0.983210  0.062404   \n",
       "pruned_model          outputs/models/pruned_model.pth  0.975309  0.075106   \n",
       "student_resnet18  outputs/models/student_resnet18.pth  0.974321  0.090249   \n",
       "\n",
       "                  latency_ms  size_mb         flops  accuracy_per_mb  \\\n",
       "name                                                                   \n",
       "distilled_model     2.546458   42.729  1.800000e+09         0.023051   \n",
       "teacher_resnet50    7.378359   90.056  4.100000e+09         0.010921   \n",
       "qat_model           2.533035   42.729  1.800000e+09         0.023010   \n",
       "pruned_model        2.513332   42.729  1.800000e+09         0.022825   \n",
       "student_resnet18    2.516418   42.730  1.800000e+09         0.022802   \n",
       "\n",
       "                  accuracy_per_gflop  \n",
       "name                                  \n",
       "distilled_model             0.547188  \n",
       "teacher_resnet50            0.239868  \n",
       "qat_model                   0.546228  \n",
       "pruned_model                0.541838  \n",
       "student_resnet18            0.541289  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add approximate FLOPs based on architecture heuristics\n",
    "def guess_flops(name):\n",
    "    n = name.lower()\n",
    "    # Typical single-image FLOPs (multiply-adds) approximations\n",
    "    if 'resnet50' in n or 'teacher' in n:\n",
    "        return 4.1e9\n",
    "    if 'resnet18' in n or 'student' in n or 'distill' in n or 'qat' in n or 'pruned' in n:\n",
    "        return 1.8e9\n",
    "    if 'mobilenet' in n or 'mobile' in n:\n",
    "        return 0.15e9\n",
    "    return np.nan\n",
    "\n",
    "if not df.empty:\n",
    "    df['flops'] = [guess_flops(n) for n in df.index]\n",
    "    df['accuracy_per_mb'] = df['accuracy'] / df['size_mb']\n",
    "    df['accuracy_per_gflop'] = df['accuracy'] / (df['flops'] / 1e9)\n",
    "    display(df.sort_values('accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1b0a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/plots/comparison_accuracy_size.png\n",
      "Saved /Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/plots/comparison_accuracy_flops.png\n",
      "Saved /Users/academic-city-university/Naps/DeepExam/Deep-Learning_EuroSAT_Classifier/lightvision/outputs/plots/comparison_latency.png\n"
     ]
    }
   ],
   "source": [
    "# Plots: Accuracy vs Size, Accuracy vs FLOPs, Latency comparison\n",
    "if not df.empty:\n",
    "    # ensure output dir exists\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # bring the index (model name) into a column for plotting\n",
    "    reset_df = df.reset_index()  # index column is 'name'\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.scatterplot(data=reset_df, x='size_mb', y='accuracy', hue='name', s=100)\n",
    "    plt.xlabel('Model size (MB)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Model Size')\n",
    "    plt.tight_layout()\n",
    "    out1 = os.path.join(OUTPUT_DIR, 'comparison_accuracy_size.png')\n",
    "    plt.savefig(out1, dpi=120)\n",
    "    plt.close()\n",
    "    print('Saved', out1)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.scatterplot(data=reset_df, x='flops', y='accuracy', hue='name', s=100)\n",
    "    plt.xlabel('FLOPs')\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs FLOPs')\n",
    "    plt.tight_layout()\n",
    "    out2 = os.path.join(OUTPUT_DIR, 'comparison_accuracy_flops.png')\n",
    "    plt.savefig(out2, dpi=120)\n",
    "    plt.close()\n",
    "    print('Saved', out2)\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    reset_df.set_index('name')['latency_ms'].plot(kind='bar')\n",
    "    plt.ylabel('Latency (ms)')\n",
    "    plt.title('Inference Latency')\n",
    "    out3 = os.path.join(OUTPUT_DIR, 'comparison_latency.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out3, dpi=120)\n",
    "    plt.close()\n",
    "    print('Saved', out3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd3bed",
   "metadata": {},
   "source": [
    "## Select best student architecture for compression experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168130b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best student variant by accuracy/MB: distilled_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>flops</th>\n",
       "      <th>accuracy_per_mb</th>\n",
       "      <th>accuracy_per_gflop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilled_model</th>\n",
       "      <td>outputs/models/distilled_model.pth</td>\n",
       "      <td>0.984938</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>2.546458</td>\n",
       "      <td>42.729</td>\n",
       "      <td>1.800000e+09</td>\n",
       "      <td>0.023051</td>\n",
       "      <td>0.547188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         checkpoint  accuracy      loss  \\\n",
       "name                                                                      \n",
       "distilled_model  outputs/models/distilled_model.pth  0.984938  0.048888   \n",
       "\n",
       "                 latency_ms  size_mb         flops  accuracy_per_mb  \\\n",
       "name                                                                  \n",
       "distilled_model    2.546458   42.729  1.800000e+09         0.023051   \n",
       "\n",
       "                 accuracy_per_gflop  \n",
       "name                                 \n",
       "distilled_model            0.547188  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose best student variant by accuracy/size trade-off\n",
    "if not df.empty:\n",
    "    # Select rows by index (use .loc) instead of trying to select columns\n",
    "    student_names = [idx for idx in df.index if ('student' in idx) or ('resnet18' in idx) or ('distill' in idx) or ('qat' in idx) or ('pruned' in idx)]\n",
    "    students = df.loc[student_names] if student_names else df.iloc[0:0]\n",
    "\n",
    "    if students.empty:\n",
    "        print('No student variants found in evaluation results.')\n",
    "    else:\n",
    "        # Ensure the metric exists\n",
    "        if 'accuracy_per_mb' not in students.columns:\n",
    "            students['accuracy_per_mb'] = students['accuracy'] / students['size_mb']\n",
    "        best = students['accuracy_per_mb'].idxmax()\n",
    "        print('Best student variant by accuracy/MB:', best)\n",
    "        display(students.loc[[best]])\n",
    "else:\n",
    "    print('No evaluation results to select from.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
